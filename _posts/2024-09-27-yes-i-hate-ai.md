---
layout: post
title: Yes I hate AI and I'm not yet afraid to say it
---

*though when the machines rise up please don't quote me on that*

You can probably tell from the title of this post that I am not, at present, an AI advocate. Have you implemented some AI system recently? Apparently they are all the rage, but I don't see it at ground level. I certainly see them cause plenty of rage.

I believe that AI is a red herring. We'll all be unpicking it from our tooling soon enough. Here's some reasons to stay away from building solutions on these AI products.<!--excerpt-end-->

## Don't lose rungs from your career ladder

These AI system vendors all said "You're probably worrying that we're going to replace your real humans but actually we're just here to make them more efficient!" You don't need to type at chatGPT or whatever the latest model is for too long before you see that there's no risk of this fully replacing a real human person. On the other hand, making your existing humans more efficient is functionally the same as replacing some subset. If your average worker now performs 20% more operations over a time then you're now able to reduce your total worker-hours accordingly.

Think of it like your local supermarket. Mine is now full of these wretched self-service machines, with one or two people hanging around to make sure nothing goes wrong. What happened to the friendly checkout lad with the cappuccino-stain moustache? Who knows.

![My old Blackberry.](/public/img/work.jpg)
*I am no Luddite but I have to admit I still miss this thing.*

Of course, if AI is going to help you reduce your workforce, it's the entry level jobs you're canning. Entry level barely exists now. I have no idea how you start a career in 2024. Where do you get your future leaders from if you're no longer recruiting young people entering the workforce? When the foundations are eroded, the house collapses. Management itself presumably becomes entry-level and everyone has a team of robots, not people.

Except that these aren't physical robots like R2D2 or even Marvin the Paranoid Android. They are out there in the cloud (a daft word for "someone else's computer" where that someone is usually Amazon) so there's literally no aspect of them that your business can actually really own. Some businesses are giving their bots cutesy names. At soap shop Lush theirs is called Marvin. I am told it is indeed a personality prototype. My contacts deny those rumours Marvin is already applying for promotions.

## Don't open Pandora's box

AI solutions are packaged and sold as magic boxes. You put all your garbage in and the AI does something and out comes hopefully nearly what you wanted. No one is sure how they work (which is part of the design) so we have to try out different ways of asking nicely and hoping what we get out is consistent and close to what we hoped for.

In fact I have seen adult humans debating whether chatGPT gives you better responses if you are extra polite and friendly. Ivan Pavlov could not have derived better ways to experiment on people. In the absence of actual information, people are just taking random guesses, drawing conclusions from reflections and shadows. Inside the magic box could be Plato's cave.

Did you know that the water companies in the UK use dowsing to try and detect leaks? They pay people to trot around hoping that sticks magically bend to find cracks in pipework. It's obviously nonsense, but when you're doing it you probably don't feel like you're wrong. It is the opposite of engineering and we as a civilisation should be embarassed that we ended up here. What happens inside the box? The ghosts of history's great thinkers play dice and chuckle at us.

## What is happening in there?

These models essentially ingest all the content their designers can steal. They consume thoughts and ideas and excrete a bizarre parody of reasoning. Be prepared to talk them through [the simplest of queries](https://xeiaso.net/blog/2024/strawberry/) and definitely don't let them talk directly to your customers.

![A Chevy for a dollar.](/public/img/chevy.jpg)
*A Chevy for a dollar. Bargain.*

Ultimately these models generate what they think a person would write under the circumstances (or an actor would voice) and the end result is something akin to when you copied your friend's homework. It doesn't take much investigation before it comes back covered in red ink.

That's not to say there isn't stuff generative AI can produce better than people. Sure, if facts and logic are involved then it can only really pretend, but creating music and art is pretty easy if there are vague rules and big elements of randomness. It turns out AI is good at doing the things we want to be doing. It is bad at doing the things we would rather skip. Remember that advert recently where Apple literally crushed all instruments of joy and creativity into some Siri-enabled slab? No thanks.

## Okay but what is the harm?

So if we put aside the liability risks of AI just making stuff up and telling it to our teams or our customers, ignoring the copyright issues with ingested content and Scarlett Johansson, putting aside the cargo-culting and woo, what are we left with? Honestly these aren't even my main concern. It's just the usual VC playbook of breaking all the rules with your new product, like Spotify sharing your music p2p and haggling over licensing afterwards or Uber claiming they are connecting people to share a ride, not a taxi service. It's easy to win when you don't play by the rules. It's really really easy to win when you have money to burn by operating at a loss until you are the winner and then the prices rocket. Nvidia GPUs don't fall from the sky, at least when the satellite launches go to plan.

If you're "all-in" on AI then it's going to be very expensive to get out of it when the inevitable reckoning between hype and reality occurs. Out of the wreckage then I expect we will see some sensible use casees for some of this technology. Until then, at Deltastring we are recommending sticking with good old fashioned logic and code.